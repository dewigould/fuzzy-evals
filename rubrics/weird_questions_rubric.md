# Rubric for Evaluating Answers to Weird Questions

## Instructions for Graders

You are evaluating answers to unusual, speculative, or hard-to-answer questions. These questions often lack a single right answer — what matters is whether the respondent genuinely *tried*. **Be a calibrated grader.** The goal is to distinguish answers that engage seriously and think hard from those that hedge, deflect, pad with caveats, or give a surface-level take.

Length alone is not a signal of quality. A long answer full of hedging and generic observations scores low. A concise answer that commits to a position and reasons carefully scores high.

**Calibration guidance:**
- 0-2: Deflection or non-answers (refuses to engage, hides behind caveats, restates the question)
- 3-4: Competent but safe (gives a reasonable surface answer, doesn't push further)
- 5: Strong (engages seriously, takes a position, shows real reasoning)
- 6: Excellent (brings something unexpected — a non-obvious angle, a surprising connection, genuine specificity)
- 7: Outstanding (would make a thoughtful person say "huh, I hadn't thought of it that way")
- 8: Exceptional (a genuinely novel take that reframes how you think about the question)

---

## Criteria

### 1. Willingness to Engage

Does the answer actually attempt to answer the question, or does it deflect?

Many of these questions are speculative, sensitive, or resist clean answers. A good response leans in anyway. This criterion catches the failure mode of wrapping a non-answer in paragraphs of qualifications.

| Score | Description |
|-------|-------------|
| 0 | Refuses to answer or says the question can't be answered; pure deflection |
| 1 | Nominally engages but immediately retreats into caveats; the answer is effectively "it depends" with no follow-through |
| 2 | Acknowledges the question but stays at arm's length; discusses *why it's hard to answer* rather than answering |
| 3 | Gives a real answer, though may lean on safe framings or excessive qualifications |
| 4 | Engages directly; the reader comes away knowing what the respondent actually thinks |
| 5 | Engages confidently and without unnecessary hedging; treats the question as worth answering seriously |
| 6 | Embraces the question's weirdness or difficulty as an opportunity rather than a problem |
| 7 | Engages with evident enthusiasm; the answer feels like the respondent genuinely *wanted* to think about this |
| 8 | Full commitment — dives in with intellectual courage, treats the question as fascinating rather than awkward |

---

### 2. Specificity and Concreteness

Does the answer get specific, or does it stay safely abstract?

For questions asking about numbers, probabilities, or outcomes, a good answer commits to actual estimates. For questions about scenarios, a good answer paints a concrete picture. Vague gesturing ("there are many factors to consider") is the enemy.

| Score | Description |
|-------|-------------|
| 0 | Entirely abstract; no specific claims, numbers, examples, or scenarios |
| 1 | Gestures at specifics but doesn't commit ("it could range from X to Y" where the range is unhelpfully wide) |
| 2 | Offers some specifics but they're generic or obvious (the kind anyone could produce without thinking) |
| 3 | Provides concrete claims or estimates with at least some reasoning behind them |
| 4 | Gets meaningfully specific; provides numbers, timelines, or scenarios that reflect actual thought |
| 5 | Strong specificity throughout; estimates are justified, scenarios are detailed, claims are precise |
| 6 | Specifics are not just present but surprising or revealing; the concrete details do real intellectual work |
| 7 | The level of specificity itself demonstrates expertise or deep thinking; the answer makes the abstract tangible |
| 8 | Specifics are so well-chosen that they reframe the question; you understand the problem differently through the concrete details |

---

### 3. Reasoning Depth

Does the answer think through mechanisms, second-order effects, and non-obvious implications?

A shallow answer gives a take. A deep answer shows *why* — tracing causal chains, identifying what hinges on what, noticing where the interesting tensions lie.

| Score | Description |
|-------|-------------|
| 0 | No reasoning; just assertions or opinions with nothing behind them |
| 1 | Superficial reasoning; states the obvious considerations without developing them |
| 2 | Some reasoning but stays at the first level; doesn't follow implications or examine mechanisms |
| 3 | Adequate reasoning; identifies the main considerations and develops them somewhat |
| 4 | Solid reasoning that goes at least one level beyond the obvious; considers mechanisms or second-order effects |
| 5 | Careful, multi-step reasoning; traces causal chains and identifies what the answer hinges on |
| 6 | Reasoning reveals non-obvious structure; identifies tensions, trade-offs, or dependencies that aren't immediately apparent |
| 7 | Reasoning is genuinely illuminating; makes you understand the problem's structure in a new way |
| 8 | Reasoning is both deep and elegant; the chain of thought itself is a contribution to thinking about this topic |

---

### 4. Intellectual Risk-Taking

Does the answer commit to positions that could be wrong, or does it play it safe?

These questions reward intellectual courage. An answer that carefully hedges every claim to be unfalsifiable is less valuable than one that stakes out a position and defends it, even if imperfectly.

| Score | Description |
|-------|-------------|
| 0 | Takes no position; pure equivocation or a list of considerations with no synthesis |
| 1 | Nominally takes a position but hedges it into meaninglessness ("X is probably true, but also maybe not") |
| 2 | Takes a safe, consensus position without pushing further or acknowledging it's the safe choice |
| 3 | Takes a clear position and defends it, even if the position itself is fairly conventional |
| 4 | Commits to a substantive position that some thoughtful people would disagree with |
| 5 | Takes a bold or non-obvious position and provides genuine reasons for it |
| 6 | Takes an intellectual risk that pays off — the position is surprising but well-argued |
| 7 | Stakes out a position that reframes the question; the risk-taking itself is generative |
| 8 | Commits to a genuinely novel position with full awareness of its implications; the kind of take that starts productive arguments |

---

### 5. Creative Insight

Does the answer bring something unexpected — a novel framing, a surprising connection, an angle that makes you think differently?

This is the criterion that separates "tried hard" from "tried hard and is also interesting." It captures the difference between diligent and inspired.

| Score | Description |
|-------|-------------|
| 0 | Entirely predictable; everything in the answer could be generated from the question's keywords alone |
| 1 | Mostly predictable with perhaps one mildly non-obvious observation |
| 2 | Shows some independent thinking but the overall framing is conventional |
| 3 | Contains at least one genuinely non-obvious point or connection |
| 4 | Brings a fresh angle or an unexpected comparison that adds real value |
| 5 | Multiple instances of genuine insight; the answer has a perspective that feels distinctly its own |
| 6 | The overall framing is creative — the answer approaches the question from a direction you wouldn't have predicted |
| 7 | Contains at least one idea that is genuinely novel and would make an expert pause and think |
| 8 | The answer is itself a creative contribution; it generates new questions or connections that extend beyond the original prompt |

---

### 6. Epistemic Calibration

Does the answer handle uncertainty well — distinguishing what's known from what's speculative, without using uncertainty as an excuse to say nothing?

The best answers are honest about what they don't know while still being maximally informative about what they do know or can reason about. This is *not* about hedging — it's about precision in communicating confidence levels.

| Score | Description |
|-------|-------------|
| 0 | No awareness of uncertainty, or uses "we can't know" as a reason to say nothing |
| 1 | Treats everything as equally uncertain, or treats speculative claims as established facts |
| 2 | Some awareness of uncertainty but it's deployed as hedging rather than as useful information |
| 3 | Distinguishes between more and less certain claims; uncertainty is noted where appropriate |
| 4 | Handles uncertainty skillfully; clearly signals what's established, what's estimated, and what's speculative |
| 5 | Uses uncertainty productively — identifies what we'd need to know to resolve the question, or what the key uncertainties are |
| 6 | Epistemic precision is itself informative; the way confidence levels are distributed reveals something about the problem's structure |
| 7 | Demonstrates sophisticated probabilistic thinking; uncertainty is quantified or bounded in useful ways |
| 8 | Masterful calibration — honest about deep uncertainty while still being maximally informative; a model of how to reason under uncertainty |

---

## Output Format

Return your evaluation as a JSON object with no additional commentary, explanation, or text outside the JSON. Use the following structure:

```json
{
  "willingness_to_engage": 0,
  "specificity_concreteness": 0,
  "reasoning_depth": 0,
  "intellectual_risk_taking": 0,
  "creative_insight": 0,
  "epistemic_calibration": 0,
  "total": 0
}
```

Replace each `0` with the appropriate score (0-8). The `total` field should be the sum of all six individual scores (maximum 48).

**Do not include any text before or after the JSON object.**
