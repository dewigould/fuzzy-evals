"""Experiment 16/02 — Llama 3.1 8B Instruct configuration.

Alternative base model config. Import this instead of config.py for Llama runs.
"""

from pathlib import Path

# ── Model ────────────────────────────────────────────────────────────────────
MODEL_NAME = "meta-llama/Llama-3.1-8B-Instruct"
LORA_RANK = 16

# ── Inference ────────────────────────────────────────────────────────────────
INFERENCE_MAX_TOKENS = 4096

# ── Training ─────────────────────────────────────────────────────────────────
TRAIN_MAX_LENGTH = 4096
TRAIN_LR = 1e-4
TRAIN_SAMPLES = 25_000
TRAIN_BATCH_SIZE = 50
TRAIN_SCHEDULE = "cosine"
SAVE_EVERY = 100
EVAL_EVERY = 100

# ── Eval sweep ───────────────────────────────────────────────────────────────
EVAL_DATASETS = ["math_500", "aime", "humanevalplus", "mbppplus"]
EVAL_CONCURRENCY = 10

# ── Paths ────────────────────────────────────────────────────────────────────
EXPERIMENT_DIR = Path(__file__).parent
RESULTS_DIR = EXPERIMENT_DIR / "results"
TRAINING_DIR = EXPERIMENT_DIR / "training_runs"

# Filtered data (generated by parent distillation/ scripts)
DISTILLATION_DIR = EXPERIMENT_DIR.parent
FILTERED_MATH_DATA = DISTILLATION_DIR / "filtered_data" / "clean.jsonl"
FILTERED_CODE_DATA = DISTILLATION_DIR / "filtered_data_kodcode" / "clean.jsonl"
