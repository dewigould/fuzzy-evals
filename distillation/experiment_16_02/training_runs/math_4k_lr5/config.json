{
  "log_path": "/workspace/fuzzy-evals/distillation/experiment_16_02/training_runs/math_4k_lr5",
  "model_name": "Qwen/Qwen3-30B-A3B-Base",
  "load_checkpoint_path": null,
  "dataset_builder": {
    "common_config": {
      "model_name_for_tokenizer": "Qwen/Qwen3-30B-A3B-Base",
      "renderer_name": "role_colon",
      "max_length": 4096,
      "batch_size": 50,
      "train_on_what": null
    },
    "buffer_size": 10000,
    "max_prompts": 25000,
    "test_size": 200,
    "filter_max_length": 4096
  },
  "learning_rate": 2e-05,
  "lr_schedule": "cosine",
  "num_epochs": 1,
  "lora_rank": 32,
  "base_url": null,
  "evaluator_builders": [],
  "infrequent_evaluator_builders": [],
  "save_every": 100,
  "eval_every": 100,
  "infrequent_eval_every": 100,
  "ttl_seconds": 604800,
  "adam_beta1": 0.9,
  "adam_beta2": 0.95,
  "adam_eps": 1e-08,
  "wandb_project": null,
  "wandb_name": null,
  "enable_trace": false
}